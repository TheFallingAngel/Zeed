#!/usr/bin/env python3
"""
é—ªä»·é›·è¾¾ - æ··åˆç­–ç•¥çˆ¬è™« v2
AI Agent å¤„ç†å¯¼èˆª + Playwright å¤„ç†æ•°æ®æå–

æ¶æ„ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    HybridCrawler                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                     â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚   AI Agent å±‚     â”‚ -> â”‚   Playwright å±‚   â”‚   â”‚
â”‚   â”‚  (Browser Use)    â”‚    â”‚    (æ•°æ®æå–)     â”‚   â”‚
â”‚   â”‚                   â”‚    â”‚                   â”‚   â”‚
â”‚   â”‚  - å¤„ç†å¼¹çª—       â”‚    â”‚  - ç»“æ„åŒ–æ•°æ®     â”‚   â”‚
â”‚   â”‚  - åœ°å€é€‰æ‹©       â”‚    â”‚  - æ‰¹é‡é‡‡é›†       â”‚   â”‚
â”‚   â”‚  - éªŒè¯ç          â”‚    â”‚  - å¿«é€Ÿå‡†ç¡®       â”‚   â”‚
â”‚   â”‚  - å¼‚å¸¸æ¢å¤       â”‚    â”‚                   â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ä½¿ç”¨æ–¹å¼:
1. å®‰è£…ä¾èµ–: pip install browser-use langchain-anthropic playwright
2. è®¾ç½® API Key: export ANTHROPIC_API_KEY=your-key
3. è¿è¡Œ: python -m crawler.hybrid_crawler
"""

import asyncio
import os
import re
import random
import json
from datetime import datetime
from typing import List, Optional, Dict, Any
from dataclasses import dataclass, asdict

# Playwright - ç”¨äºæ•°æ®æå–
from playwright.async_api import async_playwright, Page, Browser as PWBrowser, BrowserContext

# å¯¼å…¥é¡¹ç›®é…ç½®
import sys
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from config import PILOT_LOCATIONS, DEFAULT_PRODUCTS, Location

# Browser Use - å¯é€‰ä¾èµ–
HAS_BROWSER_USE = False
HAS_ANTHROPIC = False

try:
    from browser_use import Agent, Browser as BUBrowser, BrowserConfig
    HAS_BROWSER_USE = True
except ImportError:
    pass

try:
    from langchain_anthropic import ChatAnthropic
    HAS_ANTHROPIC = True
except ImportError:
    pass


@dataclass
class CrawledPrice:
    """é‡‡é›†åˆ°çš„ä»·æ ¼æ•°æ®"""
    platform: str
    shop_id: str
    shop_name: str
    shop_address: str
    distance: int
    product_name: str
    price: float
    original_price: float
    promotion: str
    in_stock: bool
    crawled_at: str
    
    def to_dict(self) -> dict:
        return asdict(self)


class HybridMeituanCrawler:
    """
    æ··åˆç­–ç•¥ç¾å›¢çˆ¬è™«
    
    ç­–ç•¥ï¼š
    1. ä½¿ç”¨ AI Agent (Browser Use) å®Œæˆå¤æ‚å¯¼èˆªï¼ˆå¯é€‰ï¼‰
    2. ä½¿ç”¨ Playwright è¿›è¡Œå¿«é€Ÿæ•°æ®æå–
    
    å¦‚æœ Browser Use ä¸å¯ç”¨ï¼Œå›é€€åˆ°çº¯ Playwright æ¨¡å¼
    """
    
    def __init__(self, use_ai: bool = True, llm_provider: str = "anthropic"):
        """
        åˆå§‹åŒ–çˆ¬è™«
        
        Args:
            use_ai: æ˜¯å¦ä½¿ç”¨ AI Agent
            llm_provider: LLM æä¾›å•† ("anthropic" æˆ– "deepseek")
        """
        # æ£€æŸ¥ AI æ˜¯å¦å¯ç”¨
        self.use_ai = use_ai and HAS_BROWSER_USE
        self.llm_provider = llm_provider
        
        # AI ç»„ä»¶
        self.bu_browser = None
        self.llm = None
        
        # Playwright ç»„ä»¶
        self.playwright = None
        self.pw_browser: Optional[PWBrowser] = None
        self.pw_context: Optional[BrowserContext] = None
        self.pw_page: Optional[Page] = None
        
        # çŠ¶æ€
        self.screenshot_count = 0
        self.location: Optional[Location] = None
        self.location_set = False
        
        # æ˜¾ç¤ºæ¨¡å¼
        if self.use_ai:
            if HAS_ANTHROPIC and os.getenv("ANTHROPIC_API_KEY"):
                print("âœ… æ··åˆæ¨¡å¼: AI Agent (Claude) + Playwright")
            elif os.getenv("DEEPSEEK_API_KEY"):
                print("âœ… æ··åˆæ¨¡å¼: AI Agent (DeepSeek) + Playwright")
                self.llm_provider = "deepseek"
            else:
                print("âš ï¸ ç¼ºå°‘ API Keyï¼Œå›é€€åˆ°çº¯ Playwright æ¨¡å¼")
                self.use_ai = False
        else:
            print("ğŸ“Œ çº¯ Playwright æ¨¡å¼")
    
    def _create_llm(self):
        """åˆ›å»º LLM å®ä¾‹"""
        if self.llm_provider == "anthropic":
            from langchain_anthropic import ChatAnthropic
            return ChatAnthropic(
                model="claude-sonnet-4-20250514",
                api_key=os.getenv("ANTHROPIC_API_KEY"),
                timeout=120,
            )
        elif self.llm_provider == "deepseek":
            from langchain_openai import ChatOpenAI
            return ChatOpenAI(
                model="deepseek-chat",
                api_key=os.getenv("DEEPSEEK_API_KEY"),
                base_url="https://api.deepseek.com/v1",
                timeout=120,
            )
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ LLM: {self.llm_provider}")
    
    async def init_browser(self, location: Location, headless: bool = True):
        """
        åˆå§‹åŒ–æµè§ˆå™¨
        
        Args:
            location: ç›®æ ‡ä½ç½®
            headless: æ˜¯å¦æ— å¤´æ¨¡å¼
        """
        self.location = location
        
        user_agent = "Mozilla/5.0 (iPhone; CPU iPhone OS 17_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Mobile/15E148 Safari/604.1"
        
        # ========== åˆå§‹åŒ– Playwright ==========
        print("ğŸŒ åˆå§‹åŒ– Playwright...")
        self.playwright = await async_playwright().start()
        
        self.pw_browser = await self.playwright.chromium.launch(
            headless=headless,
            slow_mo=50,
            args=[
                '--no-sandbox',
                '--disable-blink-features=AutomationControlled',
                '--disable-dev-shm-usage',
                '--lang=zh-CN',
            ]
        )
        
        self.pw_context = await self.pw_browser.new_context(
            viewport={"width": 375, "height": 812},
            user_agent=user_agent,
            geolocation={"latitude": location.latitude, "longitude": location.longitude},
            permissions=["geolocation"],
            locale="zh-CN",
            timezone_id="Asia/Shanghai",
            device_scale_factor=3,
            is_mobile=True,
            has_touch=True,
        )
        
        # åæ£€æµ‹è„šæœ¬
        await self.pw_context.add_init_script("""
            Object.defineProperty(navigator, 'webdriver', { get: () => undefined });
            Object.defineProperty(navigator, 'plugins', { get: () => [1, 2, 3] });
            Object.defineProperty(navigator, 'languages', { get: () => ['zh-CN', 'zh'] });
        """)
        
        self.pw_page = await self.pw_context.new_page()
        self.pw_page.set_default_timeout(30000)
        
        # ========== åˆå§‹åŒ– Browser Use (å¦‚æœå¯ç”¨) ==========
        if self.use_ai:
            try:
                print("ğŸ¤– åˆå§‹åŒ– AI Agent...")
                self.llm = self._create_llm()
                
                config = BrowserConfig(
                    headless=headless,
                    disable_security=True,
                    extra_chromium_args=[
                        '--no-sandbox',
                        '--disable-blink-features=AutomationControlled',
                        '--lang=zh-CN',
                    ],
                )
                self.bu_browser = BUBrowser(config=config)
                print("âœ… AI Agent åˆå§‹åŒ–å®Œæˆ")
                
            except Exception as e:
                print(f"âš ï¸ AI Agent åˆå§‹åŒ–å¤±è´¥: {e}")
                self.use_ai = False
        
        print(f"âœ… æµè§ˆå™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   ä½ç½®: {location.name}")
        print(f"   åœ°å€: {location.address}")
    
    async def close(self):
        """å…³é—­æ‰€æœ‰æµè§ˆå™¨"""
        if self.pw_context:
            await self.pw_context.close()
        if self.pw_browser:
            await self.pw_browser.close()
        if self.playwright:
            await self.playwright.stop()
        if self.bu_browser:
            await self.bu_browser.close()
        print("ğŸ”’ æµè§ˆå™¨å·²å…³é—­")
    
    async def _screenshot(self, name: str) -> str:
        """ä¿å­˜æˆªå›¾"""
        self.screenshot_count += 1
        path = f"debug_{self.screenshot_count:02d}_{name}.png"
        await self.pw_page.screenshot(path=path)
        return path
    
    # ==================== AI Agent æ–¹æ³• ====================
    
    async def _ai_setup_location(self) -> bool:
        """ä½¿ç”¨ AI Agent è®¾ç½®åœ°å€"""
        if not self.use_ai or not self.bu_browser or not self.location:
            return False
        
        city = "é‡åº†"
        address = self.location.address.replace("é‡åº†å¸‚å—å²¸åŒº", "")
        
        task = f"""
ä½ éœ€è¦åœ¨ç¾å›¢å¤–å–H5é¡µé¢è®¾ç½®æ”¶è´§åœ°å€ã€‚

ã€æ­¥éª¤ã€‘
1. æ‰“å¼€ https://h5.waimai.meituan.com
2. ç­‰å¾…é¡µé¢åŠ è½½ï¼Œå…³é—­æ‰€æœ‰å¼¹çª—ï¼ˆç‚¹å‡»å…³é—­æŒ‰é’®æˆ–ç©ºç™½å¤„ï¼‰
3. ç‚¹å‡»é¡µé¢é¡¶éƒ¨çš„åœ°å€æ 
4. å¦‚æœå‡ºç°åŸå¸‚é€‰æ‹©ï¼Œç‚¹å‡»"{city}"
5. åœ¨æœç´¢æ¡†è¾“å…¥"{address}"
6. ç‚¹å‡»ç¬¬ä¸€ä¸ªæœç´¢ç»“æœ
7. ç¡®è®¤è¿”å›é¦–é¡µï¼Œåœ°å€å·²æ›´æ–°

ã€æˆåŠŸæ ‡å‡†ã€‘
é¡µé¢é¡¶éƒ¨æ˜¾ç¤ºåŒ…å«"{address}"çš„åœ°å€

ã€å›å¤ã€‘
- æˆåŠŸ: SUCCESS: [æ˜¾ç¤ºçš„åœ°å€]
- å¤±è´¥: FAILED: [åŸå› ]
- éªŒè¯ç : CAPTCHA

ã€æ³¨æ„ã€‘
- ä¸­æ–‡é¡µé¢
- é‡åˆ°403å°±åˆ·æ–°é‡è¯•
- æ¯æ­¥ç­‰å¾…1-2ç§’
"""
        
        print(f"\nğŸ¤– AI è®¾ç½®åœ°å€: {city} {address}")
        
        try:
            agent = Agent(
                task=task,
                llm=self.llm,
                browser=self.bu_browser,
            )
            
            history = await agent.run(max_steps=25)
            result = str(history.final_result()) if history else ""
            
            if "SUCCESS" in result.upper():
                print(f"   âœ… AI è®¾ç½®æˆåŠŸ")
                self.location_set = True
                return True
            else:
                print(f"   âš ï¸ AI è®¾ç½®ç»“æœ: {result[:80]}")
                return False
                
        except Exception as e:
            print(f"   âŒ AI è®¾ç½®å¤±è´¥: {e}")
            return False
    
    # ==================== Playwright æ–¹æ³• ====================
    
    async def _pw_close_popups(self):
        """å…³é—­å¼¹çª—"""
        selectors = [
            '[class*="close"]', '[class*="Close"]',
            'text=Ã—', 'text=å…³é—­', 'text=å–æ¶ˆ',
            '[class*="mask"]',
        ]
        
        for selector in selectors:
            try:
                elems = await self.pw_page.query_selector_all(selector)
                for elem in elems[:3]:  # æœ€å¤šå¤„ç†3ä¸ª
                    if await elem.is_visible():
                        box = await elem.bounding_box()
                        if box and box['width'] < 100 and box['height'] < 100:
                            await elem.click()
                            await asyncio.sleep(0.3)
            except:
                continue
        
        # æŒ‰ ESC
        await self.pw_page.keyboard.press("Escape")
        await asyncio.sleep(0.2)
    
    async def _pw_setup_location_fallback(self) -> bool:
        """Playwright å›é€€æ–¹æ¡ˆï¼šè®¾ç½®ä½ç½®"""
        if not self.location:
            return False
            
        print("\nğŸ“ Playwright è®¾ç½®ä½ç½®...")
        
        try:
            # 1. æ‰“å¼€é¦–é¡µ
            await self.pw_page.goto(
                "https://h5.waimai.meituan.com",
                wait_until="domcontentloaded",
                timeout=30000
            )
            await asyncio.sleep(3)
            await self._pw_close_popups()
            await self._screenshot("home")
            
            # 2. ç‚¹å‡»åœ°å€æ 
            address_area = await self.pw_page.query_selector(
                '[class*="location"], [class*="address"], [class*="poi"]'
            )
            if address_area:
                await address_area.click()
            else:
                # ç‚¹å‡»é¡¶éƒ¨åŒºåŸŸ
                await self.pw_page.click('body', position={"x": 180, "y": 40})
            
            await asyncio.sleep(2)
            await self._screenshot("address_page")
            
            # 3. æ£€æŸ¥æ˜¯å¦éœ€è¦é€‰æ‹©åŸå¸‚
            page_text = await self.pw_page.inner_text("body")
            if "é€‰æ‹©åŸå¸‚" in page_text:
                city_btn = await self.pw_page.query_selector('text=é‡åº†')
                if city_btn:
                    await city_btn.click()
                    await asyncio.sleep(2)
            
            # 4. è¾“å…¥åœ°å€
            address = self.location.address.replace("é‡åº†å¸‚å—å²¸åŒº", "")
            input_elem = await self.pw_page.query_selector(
                'input[placeholder*="æœç´¢"], input[placeholder*="åœ°å€"], input'
            )
            if input_elem:
                await input_elem.click()
                await asyncio.sleep(0.5)
                
                # é€å­—è¾“å…¥
                for char in address:
                    await input_elem.type(char, delay=random.randint(50, 120))
                
                await asyncio.sleep(2)
                await self._screenshot("address_input")
                
                # 5. ç‚¹å‡»æœç´¢ç»“æœ
                results = await self.pw_page.query_selector_all(
                    '[class*="poi"], [class*="item"], [class*="suggest"]'
                )
                for result in results[:5]:
                    text = await result.inner_text()
                    if address in text or "å—åª" in text:
                        await result.click()
                        await asyncio.sleep(2)
                        self.location_set = True
                        print("   âœ… ä½ç½®è®¾ç½®å®Œæˆ")
                        return True
            
            return False
            
        except Exception as e:
            print(f"   âŒ ä½ç½®è®¾ç½®å¤±è´¥: {e}")
            return False
    
    async def _pw_search_product(self, keyword: str) -> List[CrawledPrice]:
        """ä½¿ç”¨ Playwright æœç´¢å•†å“å¹¶æå–ä»·æ ¼"""
        results = []
        crawled_at = datetime.now().isoformat()
        
        print(f"\nğŸ” æœç´¢: {keyword}")
        
        try:
            # 1. ç¡®ä¿åœ¨é¦–é¡µ
            current_url = self.pw_page.url
            if "waimai.meituan.com" not in current_url:
                await self.pw_page.goto(
                    "https://h5.waimai.meituan.com",
                    wait_until="domcontentloaded",
                    timeout=30000
                )
                await asyncio.sleep(2)
            
            await self._pw_close_popups()
            
            # 2. ç‚¹å‡»æœç´¢æ¡†
            search_selectors = [
                'input[placeholder*="æœ"]',
                'input[placeholder*="å•†"]',
                '[class*="search"] input',
                '[class*="search"]',
            ]
            
            search_elem = None
            for sel in search_selectors:
                elem = await self.pw_page.query_selector(sel)
                if elem and await elem.is_visible():
                    search_elem = elem
                    break
            
            if search_elem:
                await search_elem.click()
                await asyncio.sleep(1)
            
            # 3. è¾“å…¥å…³é”®è¯
            input_elem = await self.pw_page.wait_for_selector('input:visible', timeout=5000)
            if input_elem:
                await input_elem.click()
                await asyncio.sleep(0.3)
                
                # æ¸…ç©ºå¹¶è¾“å…¥
                await input_elem.fill("")
                for char in keyword:
                    await input_elem.type(char, delay=random.randint(30, 80))
                
                await asyncio.sleep(1)
                
                # 4. æ‰§è¡Œæœç´¢
                search_btn = await self.pw_page.query_selector('text=æœç´¢')
                if search_btn and await search_btn.is_visible():
                    await search_btn.click()
                else:
                    await self.pw_page.keyboard.press("Enter")
                
                # 5. ç­‰å¾…ç»“æœ
                await asyncio.sleep(4)
                await self._screenshot(f"result_{keyword}")
                
                # æ£€æŸ¥é”™è¯¯
                page_text = await self.pw_page.inner_text("body")
                if "403" in page_text or "ç³»ç»Ÿç¹å¿™" in page_text or "å‡ºäº†ç‚¹å°å·®" in page_text:
                    print("   âš ï¸ è§¦å‘åçˆ¬ï¼Œç­‰å¾…é‡è¯•...")
                    await asyncio.sleep(5)
                    await self.pw_page.reload()
                    await asyncio.sleep(3)
                
                # 6. è§£æç»“æœ
                results = await self._parse_results(keyword, crawled_at)
            
        except Exception as e:
            print(f"   âŒ æœç´¢å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
        
        return results
    
    async def _parse_results(self, keyword: str, crawled_at: str) -> List[CrawledPrice]:
        """è§£ææœç´¢ç»“æœ"""
        results = []
        
        try:
            # å°è¯•ä» JavaScript è·å–æ•°æ®
            js_data = await self.pw_page.evaluate("""
                () => {
                    // å°è¯•å¤šç§æ•°æ®æº
                    const sources = [
                        window.__INITIAL_STATE__,
                        window.__NUXT__,
                        window.__DATA__,
                        window.pageData,
                    ];
                    for (const src of sources) {
                        if (src) return { source: 'window', data: src };
                    }
                    return null;
                }
            """)
            
            if js_data and js_data.get('data'):
                print(f"   ğŸ“Š ä» JS è·å–åˆ°æ•°æ®")
            
            # ä» DOM è§£æ
            card_selectors = [
                '[class*="shopItem"]', '[class*="poi"]',
                '[class*="merchant"]', '[class*="store"]',
                '[class*="goods"]', '[class*="product"]',
                '[class*="card"]', '[class*="list"] > div',
            ]
            
            cards = []
            for sel in card_selectors:
                cards = await self.pw_page.query_selector_all(sel)
                if len(cards) > 2:
                    print(f"   æ‰¾åˆ° {len(cards)} ä¸ªç»“æœå¡ç‰‡")
                    break
            
            for i, card in enumerate(cards[:15]):
                try:
                    text = await card.inner_text()
                    lines = [l.strip() for l in text.split('\n') if l.strip()]
                    
                    if not lines:
                        continue
                    
                    # æå–åº—é“ºå
                    shop_name = lines[0][:30]
                    
                    # æå–ä»·æ ¼
                    price = 0.0
                    price_match = re.search(r'[Â¥ï¿¥]\s*(\d+\.?\d*)', text)
                    if price_match:
                        price = float(price_match.group(1))
                    
                    # æå–è·ç¦»
                    distance = 0
                    dist_match = re.search(r'(\d+\.?\d*)\s*(km|m|ç±³|å…¬é‡Œ)', text, re.I)
                    if dist_match:
                        val = float(dist_match.group(1))
                        unit = dist_match.group(2).lower()
                        if 'km' in unit or 'å…¬é‡Œ' in unit:
                            distance = int(val * 1000)
                        else:
                            distance = int(val)
                    
                    if price > 0:
                        results.append(CrawledPrice(
                            platform="meituan",
                            shop_id=f"mt_{i}_{hash(shop_name) % 10000}",
                            shop_name=shop_name,
                            shop_address="",
                            distance=distance,
                            product_name=keyword,
                            price=price,
                            original_price=price,
                            promotion="",
                            in_stock=True,
                            crawled_at=crawled_at,
                        ))
                        
                except Exception as e:
                    continue
            
            if results:
                print(f"   âœ… è§£æåˆ° {len(results)} æ¡ä»·æ ¼")
                for r in results[:3]:
                    print(f"      ğŸª {r.shop_name}: Â¥{r.price}")
            else:
                print(f"   âš ï¸ æœªè§£æåˆ°ä»·æ ¼æ•°æ®")
            
        except Exception as e:
            print(f"   âŒ è§£æå‡ºé”™: {e}")
        
        return results
    
    # ==================== å…¬å¼€ API ====================
    
    async def ensure_location_set(self) -> bool:
        """ç¡®ä¿ä½ç½®å·²è®¾ç½®"""
        if self.location_set:
            return True
        
        # å°è¯• AI è®¾ç½®
        if self.use_ai:
            success = await self._ai_setup_location()
            if success:
                return True
        
        # å›é€€åˆ° Playwright
        return await self._pw_setup_location_fallback()
    
    async def search_product(self, keyword: str) -> List[CrawledPrice]:
        """æœç´¢å•ä¸ªå•†å“"""
        # ç¡®ä¿ä½ç½®å·²è®¾ç½®
        if not self.location_set:
            await self.ensure_location_set()
        
        return await self._pw_search_product(keyword)
    
    async def crawl_products(self, products: List[str]) -> List[CrawledPrice]:
        """æ‰¹é‡é‡‡é›†å•†å“"""
        all_results = []
        
        print(f"\n{'='*60}")
        print(f"ğŸ“¦ å¼€å§‹æ‰¹é‡é‡‡é›†")
        print(f"   å•†å“æ•°: {len(products)}")
        print(f"   ä½ç½®: {self.location.name if self.location else 'N/A'}")
        print(f"{'='*60}")
        
        # ç¡®ä¿ä½ç½®è®¾ç½®
        await self.ensure_location_set()
        
        for i, product in enumerate(products):
            print(f"\n[{i+1}/{len(products)}] {product}")
            
            try:
                results = await self.search_product(product)
                all_results.extend(results)
                
                # éšæœºå»¶è¿Ÿ
                delay = random.uniform(2, 5)
                print(f"   ç­‰å¾… {delay:.1f}s...")
                await asyncio.sleep(delay)
                
            except Exception as e:
                print(f"   âŒ é‡‡é›†å¤±è´¥: {e}")
        
        print(f"\n{'='*60}")
        print(f"âœ… æ‰¹é‡é‡‡é›†å®Œæˆ")
        print(f"   æ€»è®¡: {len(all_results)} æ¡ä»·æ ¼æ•°æ®")
        print(f"{'='*60}")
        
        return all_results


# ==================== ä¾¿æ·å‡½æ•° ====================

async def crawl_prices(
    location: Location, 
    products: List[str], 
    use_ai: bool = True,
    headless: bool = True,
) -> List[CrawledPrice]:
    """
    ä¾¿æ·å‡½æ•°ï¼šé‡‡é›†æŒ‡å®šä½ç½®çš„å•†å“ä»·æ ¼
    
    Args:
        location: ç›®æ ‡ä½ç½®
        products: å•†å“åˆ—è¡¨
        use_ai: æ˜¯å¦ä½¿ç”¨ AI Agent
        headless: æ˜¯å¦æ— å¤´æ¨¡å¼
        
    Returns:
        ä»·æ ¼æ•°æ®åˆ—è¡¨
    """
    crawler = HybridMeituanCrawler(use_ai=use_ai)
    
    try:
        await crawler.init_browser(location, headless=headless)
        results = await crawler.crawl_products(products)
        return results
    finally:
        await crawler.close()


# ==================== æµ‹è¯•å‡½æ•° ====================

async def test_hybrid_crawler():
    """æµ‹è¯•æ··åˆçˆ¬è™«"""
    
    print("\n" + "ğŸš€" * 20)
    print("ğŸš€ æ··åˆç­–ç•¥çˆ¬è™«æµ‹è¯•")
    print("ğŸš€" * 20)
    
    # ç¯å¢ƒæ£€æŸ¥
    print("\nğŸ“‹ ç¯å¢ƒæ£€æŸ¥:")
    print(f"   Browser Use: {'âœ…' if HAS_BROWSER_USE else 'âŒ (pip install browser-use)'}")
    print(f"   Anthropic: {'âœ…' if HAS_ANTHROPIC else 'âŒ (pip install langchain-anthropic)'}")
    print(f"   ANTHROPIC_API_KEY: {'âœ…' if os.getenv('ANTHROPIC_API_KEY') else 'âŒ'}")
    print(f"   DEEPSEEK_API_KEY: {'âœ…' if os.getenv('DEEPSEEK_API_KEY') else 'âŒ'}")
    
    # æµ‹è¯•é…ç½®
    location = PILOT_LOCATIONS[0]  # å—åªæ­¥è¡Œè¡—
    test_products = ["å†œå¤«å±±æ³‰", "çº¢ç‰›"]
    
    print(f"\nğŸ“ æµ‹è¯•ä½ç½®: {location.name}")
    print(f"ğŸ“¦ æµ‹è¯•å•†å“: {test_products}")
    
    # åˆ›å»ºçˆ¬è™«
    use_ai = HAS_BROWSER_USE and (
        os.getenv('ANTHROPIC_API_KEY') or os.getenv('DEEPSEEK_API_KEY')
    )
    
    crawler = HybridMeituanCrawler(use_ai=use_ai)
    
    try:
        # åˆå§‹åŒ–ï¼ˆéæ— å¤´æ¨¡å¼ï¼‰
        await crawler.init_browser(location, headless=False)
        
        # é‡‡é›†
        results = await crawler.crawl_products(test_products)
        
        # æ˜¾ç¤ºç»“æœ
        print("\n" + "=" * 60)
        print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»")
        print("=" * 60)
        
        for product in test_products:
            product_results = [r for r in results if r.product_name == product]
            print(f"\n{product}: {len(product_results)} æ¡")
            for r in product_results[:3]:
                print(f"   ğŸª {r.shop_name}: Â¥{r.price} ({r.distance}m)")
        
        # ä¿å­˜ç»“æœ
        if results:
            output_file = "crawl_results.json"
            with open(output_file, "w", encoding="utf-8") as f:
                json.dump([r.to_dict() for r in results], f, ensure_ascii=False, indent=2)
            print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜: {output_file}")
        
        # ä¿æŒæµè§ˆå™¨æ‰“å¼€
        print("\nâ¸ï¸ æµè§ˆå™¨ä¿æŒæ‰“å¼€ 20 ç§’...")
        await asyncio.sleep(20)
        
    finally:
        await crawler.close()
    
    print("\nâœ… æµ‹è¯•å®Œæˆ!")


if __name__ == "__main__":
    asyncio.run(test_hybrid_crawler())
